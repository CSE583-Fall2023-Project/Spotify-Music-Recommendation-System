{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "e0fa4cd8-1ea8-4be1-b5d1-0a5954f4d60c"
   },
   "outputs": [],
   "source": [
    "# myDATools包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 依赖包的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "9df4e903-8039-4a92-b4ec-becac07f3b91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "9baa2359-8768-48d1-a387-e8e6adaa622b"
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "7ef72170-01bb-4d6f-bd46-c47fa95c5728"
   },
   "outputs": [],
   "source": [
    "#功能：读取三大报表类（资产负债表、利润表、现金流量表）数据\n",
    "#思路：按照excel的sheet_name，读取三大报表类数据中银行、证券、保险、一般工商业数据\n",
    "\n",
    "class ExcelReader:\n",
    "    \"读取三大报表类\"\n",
    "    def __init__(self, path=None):\n",
    "        self.path = path\n",
    "        self.dataAll = pd.read_excel(path,sheet_name=['General Business','Bank','Securities','Insurance'],\n",
    "                                     converters={'TICKER_SYMBOL':str,'PARTY_ID':str})\n",
    "\n",
    "    def getGB(self):\n",
    "        data_part = pd.DataFrame(self.dataAll['General Business'])\n",
    "        return(data_part)\n",
    "\n",
    "    def getBank(self):\n",
    "        data_part = pd.DataFrame(self.dataAll['Bank'])\n",
    "        return(data_part)\n",
    "\n",
    "    def getSecu(self):\n",
    "        data_part = pd.DataFrame(self.dataAll['Securities'])\n",
    "        return(data_part)\n",
    "\n",
    "    def getInsu(self):\n",
    "        data_part = pd.DataFrame(self.dataAll['Insurance'])\n",
    "        return(data_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增加时间特征（属性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "751a5a52-7210-465c-84ee-e4355f389a43"
   },
   "outputs": [],
   "source": [
    "#功能：提取并增设两个列——year和month，month\n",
    "#思路：将年份和按计算周期（DATETIME_UNITS）转换的月份加到原数据表\n",
    "\n",
    "def addDateTimeFeatures(df_s,date_column,DATETIME_UNITS):\n",
    "    \n",
    "    #提取年份year特征 \n",
    "    df_s['year'] = df_s[date_column].map(lambda x:x.year)\n",
    "    \n",
    "    #提取月份month特征\n",
    "    df_st = pd.DataFrame({'MONTH':df_s[date_column].astype(str).apply(lambda x:x[5:7])})\n",
    "    \n",
    "    #生成月份、季度、年份和半年的对应关系表\n",
    "    df_dict = pd.DataFrame({'MONTH':['01','02','03','04','05','06','07','08','09','10','11','12'],\n",
    "                            'QUARTER':['03','03','03','06','06','06','09','09','09','12','12','12'],\n",
    "                           'HALF':['06','06','06','06','06','06','12','12','12','12','12','12'],\n",
    "                           'YEAR':['12','12','12','12','12','12','12','12','12','12','12','12']})\n",
    "    \n",
    "    #合并df_month和 df_calendar\n",
    "    df_output = pd.merge(df_st,df_dict,how='left')\n",
    "    \n",
    "    df_s = df_s.reset_index()\n",
    "    \n",
    "    #新增month 列    \n",
    "    df_s['month'] = df_output[DATETIME_UNITS]\n",
    "    \n",
    "    return(df_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "94b95281-10fb-4a9b-ba7a-6354d7a7c345"
   },
   "source": [
    "# 数据规整化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宏观经济和产业数据表的规整化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "uuid": "e20cf362-1f0a-4dbc-a05a-107c24b8e884"
   },
   "outputs": [],
   "source": [
    "#功能：宏观经济和产业数据表的规整化处理\n",
    "#思路：通过读取宏观数据与行业数据，按统计周期匹配出年月、按平均汇总、通过行转列等操作，产生宏观数据\n",
    "\n",
    "def tidyMacroAndIndustryData(filename,DATETIME_UNITS):\n",
    "        \n",
    "    #读取MacroIndustry的sheet ——INDIC_DATA\n",
    "    df_indus = pd.DataFrame(pd.read_excel(filename,sheet_name=['INDIC_DATA'])['INDIC_DATA'])\n",
    "    \n",
    "    #字段名称统一改为大写\n",
    "    df_indus.columns = [x.upper() for x in df_indus.columns]\n",
    "    \n",
    "    #原表中新增 year 和 mongth两个列\n",
    "    df_indus = addDateTimeFeatures(df_indus,'PERIOD_DATE',DATETIME_UNITS)\n",
    "     \n",
    "    #生成分组统计df_indus_g    \n",
    "    df_indus_g =  df_indus.groupby(['INDIC_ID','year','month'])[['DATA_VALUE']].mean().reset_index()\n",
    "    \n",
    "    #数据类型的转换\n",
    "    df_indus_g['INDIC_ID'] = df_indus_g['INDIC_ID'].astype(str)\n",
    "     \n",
    "    #生成透视表\n",
    "    df_indus_g = df_indus_g.pivot_table(index=['year','month'],\n",
    "                                        columns=[\"INDIC_ID\"],\n",
    "                                        values=[\"DATA_VALUE\"]).reset_index()\n",
    "    #将二级索引改为一级索引\n",
    "    df_indus_g.columns = [ ''.join(col) for col in df_indus_g.columns.values]\n",
    "    \n",
    "    #缺失值的填充\n",
    "    df_indus_g = df_indus_g.fillna(method='bfill')\n",
    "    \n",
    "    return(df_indus_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公司运营数据的规整化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "3aea17e5-8c2b-43a0-a177-9de814844d31"
   },
   "outputs": [],
   "source": [
    "#功能：公司运营数据的规整化处理\n",
    "\n",
    "def tidyCompOperatingData(filename,DATETIME_UNITS):\n",
    "    \n",
    "    #读取数据\n",
    "    df_comp = pd.DataFrame(pd.read_excel(filename,\n",
    "                                         sheet_name=['EN'],\n",
    "                                         converters={'TICKER_SYMBOL':str,'PARTY_ID':str})['EN'])\n",
    "    \n",
    "    #读取列名\n",
    "    df_comp.columns = [x.lstrip().rstrip() for x in df_comp.columns] \n",
    "    \n",
    "    #按周期新增year列和Month列\n",
    "    df_comp = addDateTimeFeatures(df_comp,'END_DATE',DATETIME_UNITS)\n",
    "    \n",
    "    #分组统计\n",
    "    df_comp_g =  df_comp.groupby(['TICKER_SYMBOL','INDIC_NAME_EN','year','month'])\\\n",
    "        [['VALUE']].\\\n",
    "        sum().\\\n",
    "        reset_index()\n",
    "    \n",
    "    #改为分类变量\n",
    "    f_indic = pd.factorize(df_comp_g['INDIC_NAME_EN'])\n",
    "    \n",
    "    #新增列——指标名称'INDIC_NAME_ID'\n",
    "    df_comp_g['INDIC_NAME_ID'] =\"COMP\"+ pd.Series(f_indic[0]).astype(str)\n",
    "    \n",
    "    #定义透视表\n",
    "    df_comp_g = df_comp_g.pivot_table(index=['TICKER_SYMBOL','year','month'],\n",
    "                                      columns=[\"INDIC_NAME_ID\"],\n",
    "                                      values=[\"VALUE\"]).reset_index()\n",
    "   \n",
    "    #处理列名\n",
    "    df_comp_g.columns = [ ''.join(col) for col in df_comp_g.columns.values]\n",
    "    \n",
    "    #填充缺失值\n",
    "    df_comp_g = df_comp_g.fillna(0)\n",
    "    \n",
    "    return(df_comp_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "7d4c8bba-0c0b-4c91-90b0-c93ec0da39d0"
   },
   "outputs": [],
   "source": [
    "#功能：股票数据的规整化处理\n",
    "#思路：生成由以下列组成的数据表:TICKER_SYMBOL，year,month，CLOSE_PRICE，TURNOVER_VOL，TURNOVER_VALUE，MARKET_VALUE\n",
    "\n",
    "def tidyShareData(filename,DATETIME_UNITS):\n",
    "\n",
    "    #读取数据\n",
    "    df_shares = pd.DataFrame(pd.read_excel(filename,\n",
    "                                           sheet_name=['DATA'],\n",
    "                                           converters={'TICKER_SYMBOL':str,'PARTY_ID':str})['DATA'])\n",
    "    \n",
    "    #选择特征列\n",
    "    df_shares = df_shares[['TICKER_SYMBOL','END_DATE_','CLOSE_PRICE','TURNOVER_VOL','TURNOVER_VALUE','MARKET_VALUE']]\n",
    "    \n",
    "    df_shares.columns = ['TICKER_SYMBOL','END_DATE','CLOSE_PRICE','TURNOVER_VOL','TURNOVER_VALUE','MARKET_VALUE']\n",
    "    \n",
    "    #将'END_DATE'一列的类型改为日期类型\n",
    "    df_shares['END_DATE'] = pd.to_datetime(df_shares['END_DATE'])\n",
    "    \n",
    "    #增加时间特征列\n",
    "    df_shares = addDateTimeFeatures(df_shares,'END_DATE',DATETIME_UNITS)\n",
    "    \n",
    "    #分组统计\n",
    "    df_shares_g =  df_shares.groupby(['TICKER_SYMBOL','year','month'])\\\n",
    "        [['CLOSE_PRICE','TURNOVER_VOL','TURNOVER_VALUE','MARKET_VALUE']].\\\n",
    "        mean().\\\n",
    "        reset_index()\n",
    "    \n",
    "    return(df_shares_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "uuid": "aebc6535-45a5-48aa-aec1-8e6e69acf9f7"
   },
   "outputs": [],
   "source": [
    "#功能：资产负债表和利润表的合并与规整化处理\n",
    "\n",
    "def tidyBalanceAndIncomeData(df_BalanceSheet,df_IncomeStatement):\n",
    "     \n",
    "    #缺失值的处理\n",
    "    df_BalanceSheet.loc[:, df_BalanceSheet.dtypes == 'float64'] = \\\n",
    "        df_BalanceSheet.loc[:, df_BalanceSheet.dtypes == \"float64\"].fillna(0.00001)\n",
    "    \n",
    "    #样本选择\n",
    "    df_BalanceSheet = df_BalanceSheet[(df_BalanceSheet.MERGED_FLAG == 1)]\n",
    "    \n",
    "    #特征选择\n",
    "        #PARTY_ID_机构内部ID，END_DATE_REP_报告截止日期，REPORT_TYPE_报告类型\n",
    "    df_BalanceSheet = df_BalanceSheet[df_BalanceSheet.columns.drop([\"PARTY_ID\", \"END_DATE_REP\", \"REPORT_TYPE\"])]\n",
    "   \n",
    "    #样本排序\n",
    "        #TICKER_SYMBOL_股票代码，PUBLISH_DATE_发布时间，END_DATE_截止日期\n",
    "    df_BalanceSheet = df_BalanceSheet.sort_values(by = ['TICKER_SYMBOL', 'PUBLISH_DATE', 'END_DATE'], ascending = False)\n",
    "    \n",
    "    #重复过滤\n",
    "    df_BalanceSheet = df_BalanceSheet.drop_duplicates(['TICKER_SYMBOL', 'END_DATE'], keep='first')\n",
    "    \n",
    "    #转换数据类型\n",
    "    df_BalanceSheet[\"END_DATE\"] =pd.to_datetime(df_BalanceSheet[\"END_DATE\"])\n",
    "    \n",
    "    #重复过滤\n",
    "    df_BalanceSheet = df_BalanceSheet.drop_duplicates()\n",
    "\n",
    "\n",
    "    ##定义资产分类表_ASSET_CATEGORIES\n",
    "    ASSET_CATEGORIES=pd.DataFrame({'ORIGINAL_COLUMN_NAMES':[\"C_RESER_CB\",\"DEPOS_IN_OTH_BFI\",\"PRECI_METALS\",\"LOAN_TO_OTH_BANK_FI\",\"TRADING_FA\",\"DERIV_ASSETS\",\"PUR_RESALE_FA\",\"INT_RECEIV\",\"DISBUR_LA\",\"FINAN_LEASE_RECEIV\",\"AVAIL_FOR_SALE_FA\",\"HTM_INVEST\",\"INVEST_AS_RECEIV\",\"LT_EQUITY_INVEST\",\"INVEST_REAL_ESTATE\",\"FIXED_ASSETS\",\"CIP\",\"INTAN_ASSETS\",\"GOODWILL\",\"DEFER_TAX_ASSETS\",\"OTH_ASSETS\",\"AE\",\"AA\"],\n",
    "                                  'ASSET_CLASS':[\"CRASH_ASSETS\",\"CRASH_ASSETS\",\"INVEST_ASSETS\",\"CRASH_ASSETS\",\"INVEST_ASSETS\",\"INVEST_ASSETS\",\"INVEST_ASSETS\",\"INVEST_ASSETS\",\"LOANS_ASSETS\",\"LOANS_ASSETS\",\"INVEST_ASSETS\",\"INVEST_ASSETS\",\"LOANS_ASSETS\",\"INVEST_ASSETS\",\"INVEST_ASSETS\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\",\"OPERATION_ASSET\"]})\n",
    "\n",
    "\n",
    "    #显式列名清单\n",
    "    temp = ASSET_CATEGORIES['ORIGINAL_COLUMN_NAMES'].values\n",
    "\n",
    "    #在列名清单中增加两个列'TICKER_SYMBOL', 'END_DATE'\n",
    "    temp = np.append(temp, ['TICKER_SYMBOL', 'END_DATE'])\n",
    "    \n",
    "    #按照新的列名清单对数据框df_BalanceSheet_Bank进行切片处理\n",
    "    temp = df_BalanceSheet[temp]\n",
    "\n",
    "    ##改变df_BalanceSheet_Bank1的形状，id为'TICKER_SYMBOL', 'END_DATE'\n",
    "    temp = pd.melt(temp, \n",
    "                   id_vars=['TICKER_SYMBOL', 'END_DATE'],\n",
    "                   var_name='ORIGINAL_COLUMN_NAMES',\n",
    "                   value_name='valuenum')\n",
    "\n",
    "    #合并df_BalanceSheet_Bank2和 ASSET_CATEGORIES\n",
    "    temp = pd.merge(temp, ASSET_CATEGORIES, how='left', on='ORIGINAL_COLUMN_NAMES')\n",
    "\n",
    "    #按资产类型分组统计\n",
    "    temp = temp.groupby(['TICKER_SYMBOL','END_DATE', 'ASSET_CLASS'], as_index=False)['valuenum'].sum()\n",
    "    \n",
    "    #产生分组统计的透视表\n",
    "    temp = (temp.pivot_table(index=['TICKER_SYMBOL','END_DATE'], \n",
    "                             columns='ASSET_CLASS', \n",
    "                             values='valuenum').reset_index())\n",
    "\n",
    "\n",
    "    #读取数值型列\n",
    "    temp1_name=df_BalanceSheet.columns[df_BalanceSheet.dtypes=='float64']\n",
    "    temp1=df_BalanceSheet[temp1_name]\n",
    "\n",
    "    #读取两列——'TICKER_SYMBOL','END_DATE'的值\n",
    "    temp1_label=df_BalanceSheet[['TICKER_SYMBOL','END_DATE']]\n",
    "\n",
    "    #每一类资产在总资产的占比\n",
    "    temp1_T_ASSETS=np.array([[w]*temp1.shape[1] for w in temp1.T_ASSETS])\n",
    "    temp1_T_ASSETS=temp1/temp1_T_ASSETS\n",
    "    \n",
    "    #删除两列——T_ASSETS和T_LIAB_EQUITY\n",
    "    temp1_T_ASSETS=temp1_T_ASSETS[temp1_T_ASSETS.columns.drop(['T_ASSETS','T_LIAB_EQUITY'])]\n",
    "    \n",
    "    #每个列名前加前缀T_ASSETS\n",
    "    temp1_T_ASSETS.columns=np.char.add('T_ASSETS_',list(temp1_T_ASSETS.columns))\n",
    "    \n",
    "    ## 合并id和values列，即 Percentage_OF_TotalAseets 和 df_BalanceSheet_Bank_idcolumns\n",
    "    temp1_T_ASSETS=pd.concat([temp1_label,temp1_T_ASSETS],axis=1)\n",
    "\n",
    "    temp1_T_ASSETS.columns.value_counts()\n",
    "\n",
    "    #所有列/字段在总负债的占比\n",
    "    temp1_T_LIAB=np.array([[w]*temp1.shape[1] for w in temp1.T_LIAB])\n",
    "    temp1_T_LIAB=temp1/temp1_T_LIAB\n",
    "    temp1_T_LIAB=temp1_T_LIAB[temp1_T_LIAB.columns.drop(['T_LIAB','T_LIAB_EQUITY'])]\n",
    "    temp1_T_LIAB.columns=np.char.add('T_LIAB_',list(temp1_T_LIAB.columns))\n",
    "    temp1_T_LIAB=pd.concat([temp1_label,temp1_T_LIAB],axis=1)\n",
    "\n",
    "    #所有字段在所有者权益的占比\n",
    "    temp1_T_SH_EQUITY=np.array([[w]*temp1.shape[1] for w in temp1.T_SH_EQUITY])\n",
    "    temp1_T_SH_EQUITY=temp1/temp1_T_SH_EQUITY\n",
    "    temp1_T_SH_EQUITY=temp1_T_SH_EQUITY[temp1_T_SH_EQUITY.columns.drop(['T_SH_EQUITY','T_LIAB_EQUITY'])]\n",
    "    temp1_T_SH_EQUITY.columns=np.char.add('T_SH_EQUITY_',list(temp1_T_SH_EQUITY.columns))\n",
    "\n",
    "    temp1_T_SH_EQUITY=pd.concat([temp1_label,temp1_T_SH_EQUITY],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #合并基础资产表以及资产分类表\n",
    "    df_BalanceSheet = pd.merge(df_BalanceSheet, temp, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    \n",
    "    #功能：计算增速\n",
    "    #思路：构建计算增速特征的函数，根据shiftnum的取值，计算各季度增速\n",
    "    def growthcal(data, shiftnum, groupcol, igcol):\n",
    "        datacolname = list(data.columns)\n",
    "        igcol = np.append(groupcol, igcol)\n",
    "        colname_need_cal = [x for x in datacolname if x not in igcol]\n",
    "        results = data.loc[:, groupcol]\n",
    "        for i in colname_need_cal:\n",
    "            calcol = np.append(groupcol, i)\n",
    "            columndel = np.append(i, 'B_shifted')\n",
    "            temp = data.loc[:, calcol]\n",
    "            temp2 = temp.copy()\n",
    "            temp.END_DATE = temp.END_DATE + pd.DateOffset(months = shiftnum)\n",
    "            temp.columns = np.append(groupcol, ['B_shifted'])\n",
    "            uu = temp.loc[(temp['END_DATE'].dt.month == 12) & (temp['END_DATE'].dt.day == 30), ]\n",
    "            if len(uu) > 0 :\n",
    "                temp.loc[(temp['END_DATE'].dt.month == 12) & (temp['END_DATE'].dt.day == 30), 'END_DATE'] = temp.loc[(temp['END_DATE'].dt.month == 12) & (temp['END_DATE'].dt.day==30), 'END_DATE'] + pd.DateOffset(days = 1)\n",
    "            uu = temp.loc[(temp['END_DATE'].dt.month == 3) & (temp['END_DATE'].dt.day == 30), 'END_DATE']\n",
    "            if len(uu) > 0 :\n",
    "                temp.loc[(temp['END_DATE'].dt.month == 3) & (temp['END_DATE'].dt.day == 30), 'END_DATE'] = temp.loc[(temp['END_DATE'].dt.month == 3) & (temp['END_DATE'].dt.day==30), 'END_DATE'] + pd.DateOffset(days = 1)\n",
    "            temp2 = pd.merge(temp2, temp, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "            growthname = [i + '_GROWTH' + str(shiftnum)]\n",
    "            growthname = growthname[0]\n",
    "            temp2[growthname] = temp2[i].squeeze() / temp2.B_shifted -1\n",
    "            temp2.drop(columndel, axis=1, inplace=True)\n",
    "            results = pd.merge(results, temp2, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "        return results\n",
    "\n",
    "    ##FISCAL_PERIOD_会计区间，MERGED_FLAG_合并标志，PUBLISH_DATE_发布时间，EXCHANGE_CD_交易市场代码\n",
    "    #计算同比增速\n",
    "    bsgrowth12 = growthcal(data = df_BalanceSheet, shiftnum = 12,\n",
    "                       groupcol = ['TICKER_SYMBOL', 'END_DATE'],\n",
    "                       igcol = ['EXCHANGE_CD', 'PUBLISH_DATE', 'FISCAL_PERIOD', 'MERGED_FLAG'])\n",
    "    #计算同三个季度的增速\n",
    "    bsgrowth9 = growthcal(data = df_BalanceSheet, shiftnum = 9,\n",
    "                       groupcol = ['TICKER_SYMBOL', 'END_DATE'],\n",
    "                       igcol = ['EXCHANGE_CD', 'PUBLISH_DATE', 'FISCAL_PERIOD', 'MERGED_FLAG'])\n",
    "    #计算半年同比增速\n",
    "    bsgrowth6 = growthcal(data = df_BalanceSheet, shiftnum = 6,\n",
    "                       groupcol = ['TICKER_SYMBOL', 'END_DATE'],\n",
    "                       igcol = ['EXCHANGE_CD', 'PUBLISH_DATE', 'FISCAL_PERIOD', 'MERGED_FLAG'])\n",
    "    #计算环比增速\n",
    "    bsgrowth3 = growthcal(data = df_BalanceSheet, shiftnum = 3,\n",
    "                       groupcol = ['TICKER_SYMBOL', 'END_DATE'],\n",
    "                       igcol = ['EXCHANGE_CD', 'PUBLISH_DATE', 'FISCAL_PERIOD', 'MERGED_FLAG'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #利润表的处理\n",
    "    \n",
    "    df_IncomeStatement.loc[:, df_IncomeStatement.dtypes == 'float64'] = \\\n",
    "        df_IncomeStatement.loc[:, df_IncomeStatement.dtypes == \"float64\"].fillna(0.00001)\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement[(df_IncomeStatement.MERGED_FLAG == 1)]\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement[df_IncomeStatement.columns.drop([\"PARTY_ID\", \"END_DATE_REP\", \"REPORT_TYPE\"])]\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement.sort_values(by = ['TICKER_SYMBOL', 'PUBLISH_DATE', 'END_DATE'],\n",
    "                                                        ascending = False)\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement.drop_duplicates(['TICKER_SYMBOL', 'END_DATE'],\n",
    "                                                            keep='first')\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement[df_IncomeStatement.columns.drop([\"EXCHANGE_CD\", \"PUBLISH_DATE\", \"FISCAL_PERIOD\", \"MERGED_FLAG\"])]\n",
    "\n",
    "\n",
    "\n",
    "    df_IncomeStatement['year'] = df_IncomeStatement.END_DATE.str.slice(start = 0, stop = 4)\n",
    "\n",
    "    df_IncomeStatement['month'] = df_IncomeStatement.END_DATE.str.slice(start = 5, stop = 7)\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_IncomeStatement_Q = pd.melt(df_IncomeStatement, \n",
    "                                   id_vars=['TICKER_SYMBOL', 'END_DATE', \"year\", \"month\"],\n",
    "                                   var_name='ORIGINAL_COLUMN_NAMES',\n",
    "                                   value_name='valuenum')\n",
    "    \n",
    "    df_IncomeStatement_Q[\"END_DATE\"] = df_IncomeStatement_Q[\"END_DATE\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "\n",
    "    df_IncomeStatement_Q = df_IncomeStatement_Q.sort_values(by = ['TICKER_SYMBOL', 'ORIGINAL_COLUMN_NAMES', 'END_DATE'],\n",
    "                                                            ascending = True)\n",
    "\n",
    "    \n",
    "    new_column = df_IncomeStatement_Q.groupby(['TICKER_SYMBOL','ORIGINAL_COLUMN_NAMES', 'year'],\n",
    "                                              as_index=False)['valuenum'].diff()\n",
    "\n",
    "    df_IncomeStatement_Q[\"diffs\"] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "    df_IncomeStatement_Q[\"Qvaluenum\"] = df_IncomeStatement_Q.diffs.fillna(df_IncomeStatement_Q.valuenum)\n",
    "\n",
    "    df_IncomeStatement_Q = df_IncomeStatement_Q[df_IncomeStatement_Q.columns.drop(['valuenum', 'diffs'])]\n",
    "\n",
    "    df_IncomeStatement_Q = (df_IncomeStatement_Q.pivot_table(index=['TICKER_SYMBOL','END_DATE', \"year\", \"month\"], columns='ORIGINAL_COLUMN_NAMES', values='Qvaluenum').reset_index())\n",
    "\n",
    "    df_IncomeStatement_Q  = df_IncomeStatement_Q.sort_values(by = ['TICKER_SYMBOL', 'END_DATE'],ascending = True)\n",
    "\n",
    "\n",
    "    ab_names=list(df_IncomeStatement_Q.columns)\n",
    "    ab_names=[i+'_Q1' for i in ab_names if i not in ['TICKER_SYMBOL','END_DATE', \"year\", \"month\"]]\n",
    "    ab_names = np.append(['TICKER_SYMBOL','END_DATE', \"year\", \"month\"],ab_names)\n",
    "    df_IncomeStatement_Q.columns = ab_names\n",
    "\n",
    "\n",
    "    df_IncomeStatement[\"END_DATE\"] = df_IncomeStatement[\"END_DATE\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "    df_IncomeStatement_Q=pd.merge(df_IncomeStatement_Q,df_IncomeStatement, \n",
    "                                  how='left',\n",
    "                                  on=['TICKER_SYMBOL','END_DATE', \"year\", \"month\"])\n",
    "\n",
    "\n",
    "    #银行数据合并--资产负债以及利润表\n",
    "    temp_data=pd.merge(df_BalanceSheet,temp1_T_ASSETS, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,temp1_T_LIAB, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,temp1_T_SH_EQUITY, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,bsgrowth3, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,bsgrowth6, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,bsgrowth9, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,bsgrowth12, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=pd.merge(temp_data,df_IncomeStatement_Q, how='left', on=[\"TICKER_SYMBOL\",\"END_DATE\"])\n",
    "\n",
    "    temp_data=temp_data.fillna(0)\n",
    "\n",
    "\n",
    "    del temp1_T_ASSETS\n",
    "    del temp1_T_LIAB\n",
    "    del temp1_T_SH_EQUITY\n",
    "    del bsgrowth3\n",
    "    del bsgrowth6\n",
    "    del bsgrowth9\n",
    "    del bsgrowth12\n",
    "    del df_IncomeStatement_Q\n",
    "\n",
    "\n",
    "    df_IncomeStatement=temp_data\n",
    "    \n",
    "    df_IncomeStatement=df_IncomeStatement.fillna(0)\n",
    "\n",
    "\n",
    "    df_IncomeStatement = df_IncomeStatement.sort_values(['TICKER_SYMBOL','END_DATE'])\n",
    "    \n",
    "    df_IncomeStatement = df_IncomeStatement.drop(['PUBLISH_DATE','EXCHANGE_CD','MERGED_FLAG','FISCAL_PERIOD'],1)\n",
    "    \n",
    "    return(df_IncomeStatement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "c10df322-3f20-46d5-937a-2f9e773824c2"
   },
   "source": [
    "# 数据分箱处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "21f1984f-cab8-4fb3-9a9e-91464d68dbcb"
   },
   "outputs": [],
   "source": [
    "#功能：处理极值，进行百分位离散化\n",
    "#思路：通过箱图处理极值，利用pd.qcut函数按照数据出现频率百分比划分，将极值离散化，来减弱极值对最终结果的影响\n",
    "\n",
    "def biningData(sr,n_Quantile,is_onehot):\n",
    "    \n",
    "    #分箱处理\n",
    "    df_bins = pd.qcut(sr,n_Quantile,duplicates = 'drop').to_frame()\n",
    "     #pandas.qcut:基于分位数的离散化函数。Quantile-based discretization function.\n",
    "        #第一个参数：x为被分箱处理的数据，必须为1d ndarray or Series\n",
    "        #第二个参数：n_Quantile为分位数\n",
    "        #第三个参数：duplicates如有重复值如何处理\n",
    "        \n",
    "    df_bins['DIS_'+sr.name] = pd.Categorical(df_bins.iloc[:,0]).codes\n",
    "    if(is_onehot==True):\n",
    "        df_bins['DIS_'+sr.name]=df_bins['DIS_'+sr.name].astype('category')\n",
    "    return(df_bins['DIS_'+sr.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "5c487f12-487a-4f92-871f-0489423219a3"
   },
   "outputs": [],
   "source": [
    "#功能：对每个列进行分箱处理，并为分箱给出排名号码\n",
    "\n",
    "def biningAndRankingData(df,n_Quantile,is_onehot):\n",
    "    print('————调用函数biningAndRankingData，开始为每个分箱分配排名值——————')\n",
    "    bin_columns = ['DIS_'+ i for i in df.columns]\n",
    "    rank_columns = ['RANK_'+ i for i in df.columns]\n",
    "    \n",
    "    if(is_onehot==True):\n",
    "        df_bins = df.apply(lambda x:biningData(x,n_Quantile=n_Quantile,is_onehot=is_onehot))\n",
    "        df_bins.columns = bin_columns\n",
    "        df_bins = pd.get_dummies(df_bins, prefix=bin_columns)\n",
    "    else:\n",
    "        df_bins = df.apply(lambda x:biningData(x,n_Quantile=n_Quantile,is_onehot=is_onehot))\n",
    "        df_bins.columns = bin_columns\n",
    "        \n",
    "    #为每个分箱分配排名值\n",
    "    df_bins[rank_columns] = df.rank(method = 'min')\n",
    "    return(df_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "da5d971b-3d21-4590-ae82-c76041cd035d"
   },
   "outputs": [],
   "source": [
    "#功能：产生偏移数据\n",
    "#思路：根据n_lag的设置进行几节数据偏移\n",
    "\n",
    "def featureEngineeringTimeSeriesData(df_s,n_lag):\n",
    "    print('————调用函数featureEngineeringTimeSeriesData，生成窗口特征——————')\n",
    "    list_col = df_s.columns[2:]\n",
    "    df_append =  []\n",
    "    for i in range(n_lag):\n",
    "        df_tmp = df_s.groupby(['TICKER_SYMBOL'])[list_col].shift(i+1)\n",
    "        list_col_target = [col+'_'+'LAG'+str(i+1) for col in df_tmp.columns]\n",
    "        df_tmp.columns = list_col_target\n",
    "        df_append.append(df_tmp)\n",
    "    df_s = pd.concat(df_append, axis=1)\n",
    "    del df_append\n",
    "    del df_tmp\n",
    "    gc.collect()\n",
    "    return(df_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "387b2087-14b6-4373-af4b-9f15e3484db7"
   },
   "source": [
    "# 特征矩阵的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "uuid": "325132e8-a254-427c-94fb-c20399ef2988"
   },
   "outputs": [],
   "source": [
    "#功能：特征矩阵构建\n",
    "\n",
    "def createFeatureMatrix(df_IncomeStatement,df_indus_g,df_comp_g,df_share_g,START_DATE=pd.Timestamp('2008-01-01'),\n",
    "                  IS_ONEHOT=False,N_QUANTILES=100,N_LAG=5):\n",
    "    \n",
    "    df_IncomeStatement['TICKER_SYMBOL'] = df_IncomeStatement['TICKER_SYMBOL'].astype(str)\n",
    "    df_comp_g['TICKER_SYMBOL'] = df_comp_g['TICKER_SYMBOL'].astype(str)\n",
    "    df_share_g['TICKER_SYMBOL'] = df_share_g['TICKER_SYMBOL'].astype(str)\n",
    "    df_IncomeStatement['year'] = df_IncomeStatement['year'].astype(str)\n",
    "    df_indus_g['year'] = df_indus_g['year'].astype(str)\n",
    "    df_comp_g['year'] = df_comp_g['year'].astype(str)\n",
    "    df_share_g['year'] = df_share_g['year'].astype(str)\n",
    "    df_IncomeStatement['month'] = df_IncomeStatement['month'].astype(str)\n",
    "    df_indus_g['month'] = df_indus_g['month'].astype(str)\n",
    "    df_comp_g['month'] = df_comp_g['month'].astype(str)\n",
    "    df_share_g['month'] = df_share_g['month'].astype(str)\n",
    "    print('*合并..............')\n",
    "    #df_train = pd.merge(list_company,df_IncomeStatement,how='left',on=['TICKER_SYMBOL'])\n",
    "    df_train = pd.merge(df_IncomeStatement,df_comp_g,how='left',on=['TICKER_SYMBOL','year', 'month']).fillna(0)\n",
    "    df_train = pd.merge(df_train,df_indus_g,how='left',on=['year', 'month']).fillna(0)\n",
    "    df_train = pd.merge(df_train,df_share_g,how='left',on=['TICKER_SYMBOL','year', 'month']).fillna(0)\n",
    "    del df_indus_g\n",
    "    del df_comp_g\n",
    "    del df_share_g\n",
    "    del df_IncomeStatement\n",
    "    gc.collect()\n",
    "    #筛选时间\n",
    "    df_train = df_train[df_train['END_DATE']>=START_DATE]\n",
    "    print('*删除方差为0的变量......')\n",
    "    #删除方差为0的变量***\n",
    "    #df_train['OTH_EFFECT_OP'] = 1\n",
    "    df_train = df_train.drop(['year','month'],1).sort_values(['TICKER_SYMBOL','END_DATE'])\n",
    "    df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    df_train = df_train.groupby(\"TICKER_SYMBOL\").apply(lambda x:x.ffill())\n",
    "    sr_var = df_train.var(axis =0)\n",
    "    kill_col = sr_var[sr_var<=0.0000001]\n",
    "    df_train = df_train.drop(kill_col.index,1)\n",
    "    df_train.to_csv('Data/df_train.csv')\n",
    "\n",
    "    #时间窗口特征\n",
    "    df_train_lag = featureEngineeringTimeSeriesData(df_train,N_LAG)\n",
    "    df_train_f =  pd.concat([df_train,df_train_lag],axis=1)\n",
    "    del df_train_lag\n",
    "    gc.collect()\n",
    "\n",
    "    #对每个列进行分箱处理，并按分箱为单位排名\n",
    "    #df_train_f = pd.read_csv('df_train_f.csv')\n",
    "    df_dis_rank = biningAndRankingData(df_train.iloc[:,2:],n_Quantile=N_QUANTILES,is_onehot=IS_ONEHOT)#排序\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "    df_train_f =  pd.concat([df_train_f,df_dis_rank],axis=1)\n",
    "    del df_dis_rank\n",
    "    gc.collect()\n",
    "    df_train_f = df_train_f.fillna(0)\n",
    "    \n",
    "    return(df_train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "775efa2f-b94c-4408-897d-7fae50caabf2"
   },
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "c5924e42-4d44-43ec-a469-055bec04f928"
   },
   "outputs": [],
   "source": [
    "#功能：特征筛选\n",
    "#思路：按照特征选择比例为0.8，因子筛选：树数量为100，选择因子前99.99%的重要性进行变量筛选\n",
    "\n",
    "def selectFeatures(df,pro,n_estimators=500,max_features=0.8):\n",
    "    #pro：累计重要性的选择比例= 0.99 \n",
    "    #n_estimators：树数量\n",
    "    #max_features： 特征选择比例\n",
    "    df = df.sort_values(by = ['TICKER_SYMBOL', 'END_DATE'], ascending = True)\n",
    "    df['target_REVENUE_Q1'] = df.groupby(['TICKER_SYMBOL'])['REVENUE_Q1'].shift(-1)\n",
    "    X = df[pd.notnull(df['target_REVENUE_Q1'])].iloc[:,2:-1].values\n",
    "    Y = df[pd.notnull(df['target_REVENUE_Q1'])].iloc[:,-1].values\n",
    "    names = df.iloc[:,2:-1].columns.values\n",
    "    rf = RandomForestRegressor(n_estimators = n_estimators,max_features=max_features,oob_score=True,n_jobs=-1)\n",
    "    print(rf)\n",
    "    rf.fit(X, Y)\n",
    "    col_select = pd.DataFrame({'COL':names,'IMP':rf.feature_importances_}).sort_values('IMP',ascending=False)\n",
    "    col_select['CUM_IMP'] = col_select['IMP'].cumsum()\n",
    "    pro = pro if col_select['IMP'][0:1].values[0]<pro else col_select['IMP'][0:1].values[0]\n",
    "    col_select = col_select[col_select['CUM_IMP']<=pro]\n",
    "\n",
    "    print('特征选择结果：%d个特征，累计%.7f%%的重要性。'%(col_select.shape[0],pro*100))\n",
    "    col_s = col_select['COL']\n",
    "    if(col_select[col_select['COL']=='MARKET_VALUE'].shape[0]==0):\n",
    "        col_s = pd.Series('MARKET_VALUE').append(col_s)\n",
    "    if(col_select[col_select['COL']=='REVENUE_Q1'].shape[0]==0):\n",
    "        col_s = pd.Series('REVENUE_Q1').append(col_s)\n",
    "    names_col = pd.Series(['TICKER_SYMBOL','END_DATE']).append(col_s).append(pd.Series('target_REVENUE_Q1'))\n",
    "    df = df[names_col]\n",
    "    \n",
    "    #保存临时结果\n",
    "    df.to_csv(\"Data/df_bank.csv\")\n",
    "    \n",
    "    return(df,col_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "e62f3a4b-0047-4d36-843c-6ad807e5039c"
   },
   "source": [
    "# 模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "075aa225-22f7-4532-8935-a24d5cb9d3a3"
   },
   "outputs": [],
   "source": [
    "#功能：模型融合\n",
    "#思路：确定使用的模型与权重，进行模型的生成与预测\n",
    "\n",
    "class EnsembleLearners(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, mod, weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X): \n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model, data] * weight for model, weight in zip(range(pred.shape[0]), self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "ca31f82f-e541-4d23-b700-ea05ee7302eb"
   },
   "source": [
    "# 模型训练与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "uuid": "0e0cd4b1-6dd2-466d-bf00-c1f64be8ee2c"
   },
   "outputs": [],
   "source": [
    "#功能：模型训练预测\n",
    "#思路：对所有的银行数据的目标变量进行对数log10变换，对特征集进行归一化，\n",
    "    #根据AlgorithmsInEL的值确定模型与权重，\n",
    "    #集成 ExtraTreesRegressor、GradientBoostingRegressor、RandomForestRegressor、XGBRegressor等算法\n",
    "    #根据各自的n_estimators、max_features进行模型训练，得出预测数据。\n",
    "\n",
    "def trainModel(df,LOG_N,gbr_EST,gbr_FEAT,gbr_LRAT,etr_EST,etr_FEAT,rf_EST,rf_FEAT,xgb_EST,xgb_SAM,xgb_LRAT,AlgorithmsInEL):\n",
    "    \n",
    "    df.END_DATE = df['END_DATE'].astype(\"datetime64[ns]\")\n",
    "    if(AlgorithmsInEL==0):\n",
    "        df = df.loc[df['END_DATE'].dt.month == 3,]\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    X_test = df.loc[(df['target_REVENUE_Q1'].isnull()) & (df['END_DATE'] == '2018-03-31'), ]\n",
    "    X_test.drop('target_REVENUE_Q1', axis=1, inplace=True)\n",
    "\n",
    "    X = df.loc[(df['target_REVENUE_Q1'] > 0.), ]\n",
    "    y = X['target_REVENUE_Q1']\n",
    "    X.drop('target_REVENUE_Q1', axis=1, inplace=True)\n",
    "\n",
    "    X.loc[:, X.dtypes == 'float64'] = X.loc[:, X.dtypes == \"float64\"].fillna(0.00001)\n",
    "    cols = [i for i in df.columns if i not in ['TICKER_SYMBOL', 'END_DATE', 'target_REVENUE_Q1']]\n",
    "    X = X[cols]\n",
    "\n",
    "    y = y / 10000.0\n",
    "    log_y = np.log(y)/np.log(LOG_N)\n",
    "\n",
    "    scaler = MinMaxScaler() \n",
    "    scaler.fit(df[cols])\n",
    "    \n",
    "    \n",
    "    xgb = XGBRegressor(n_estimators = xgb_EST, subsample=xgb_SAM, learning_rate = xgb_LRAT)\n",
    "    extra = ExtraTreesRegressor(n_estimators = etr_EST, max_features= etr_FEAT)\n",
    "    gbr = GradientBoostingRegressor(n_estimators = gbr_EST, max_features= gbr_FEAT, learning_rate = gbr_LRAT)\n",
    "    rf = RandomForestRegressor(n_estimators = rf_EST, max_features= rf_FEAT)\n",
    "\n",
    "    # 根据需求选择不同的集成学习方案\n",
    "    if(AlgorithmsInEL == 0):\n",
    "        print([extra,rf])\n",
    "        ensembleModel = EnsembleLearners(mod=[extra,rf], weight= [0.5,0.5])\n",
    "    elif(AlgorithmsInEL == 1):\n",
    "        print([gbr,xgb])\n",
    "        ensembleModel = EnsembleLearners(mod=[gbr,xgb], weight= [0.5,0.5])\n",
    "    elif(AlgorithmsInEL == 2):\n",
    "        print([extra,gbr,rf,xgb])\n",
    "        ensembleModel = EnsembleLearners(mod=[extra,gbr,rf,xgb], weight= [0.25,0.25,0.25,0.25])\n",
    "\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    #模型预测\n",
    "    ensembleModel.fit(X_scaled,log_y)\n",
    "    to_pred_x = X_test[cols]\n",
    "    to_pred_scaled_x = scaler.transform(to_pred_x)\n",
    "    \n",
    "    pred = np.power(LOG_N, ensembleModel.predict(to_pred_scaled_x)) * 10000.\n",
    "\n",
    "    submit_symbols = list(X_test.TICKER_SYMBOL)\n",
    "    submit_results = list((np.array(X_test.REVENUE_Q1) + np.array(pred)) / 1000000.)\n",
    "    submit_results = [float('%.2f' % w) for w in submit_results]\n",
    "\n",
    "    res = pd.DataFrame({'TICKER_SYMBOL': submit_symbols, 'PRED': submit_results})\n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "6f65c760-345b-4eba-87c1-1079a93aa3e0"
   },
   "source": [
    "# 预测结果的提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "uuid": "da0a08b9-d786-454e-bc51-1586bd53fd2a"
   },
   "outputs": [],
   "source": [
    "#功能：得出预测结果\n",
    "#思路：将预测数据合并，输出预测结果\n",
    "\n",
    "def appendPredictToSubmit(df_FDDC_financial_submit,df_bank_predicted):\n",
    "    \n",
    "    df_submit_with_predict = pd.merge(df_FDDC_financial_submit,\n",
    "                                      df_bank_predicted,\n",
    "                                      how='left',\n",
    "                                      on=['TICKER_SYMBOL'])\n",
    "     \n",
    "    df_submit_with_predict['TICKER_SYMBOL'] = df_submit_with_predict['TICKER_SYMBOL']+ \\\n",
    "                                        '.'+df_submit_with_predict['StockExchange']\n",
    "    \n",
    "    df_submit_with_predict = df_submit_with_predict.drop(['StockExchange'],1)\n",
    "\n",
    "    return(df_submit_with_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "c29de852-ca21-4e82-8e69-439bad41740f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
